# I-Built-My-Own-AutoML-System
I Built My Own AutoML System (And Learned More Than From Any Single MLÂ Model) Most machine learning tutorials teach you how to train a model. Â But real-world ML is not about one modelâ€Š-â€Šit's about deciding which model to use.

############################
ğŸš€ AutoML-Lite Platform
ğŸ“Œ Overview
AutoML-Lite is a lightweight, end-to-end automated machine learning system for tabular datasets.
It automatically detects the machine learning task, preprocesses data, trains multiple models, evaluates them, and selects the best model using both performance and production-aware logic.

This project focuses on correct ML engineering practices, not just achieving high accuracy.

ğŸ¯ Objective
The goal of this project is to:

Build a generic ML pipeline that works on unknown datasets
Reduce manual preprocessing errors
Prevent data leakage
Handle mixed data types safely
Select models intelligently instead of blindly
ğŸ” What This Project Does
Given a CSV dataset and a target column, the system:

Cleans the dataset
Detects whether the task is classification or regression
Preprocesses numeric and categorical features correctly
Trains multiple suitable ML models
Evaluates models using appropriate metrics
Selects the best model using performance + practicality
Produces a deployable ML pipeline
ğŸ” System Flow (High Level)
Load CSV â†“ Select Target Column â†“ Drop Rows with Missing Target â†“ Detect Task Type (Classification / Regression) â†“ Feature Profiling â”œâ”€ Numeric Features â””â”€ Categorical Features â””â”€ Drop High-Cardinality Columns â†“ Preprocessing Pipeline â”œâ”€ Numeric: Impute + Scale â””â”€ Categorical: Impute + Encode (Sparse) â†“ Train-Test Split â†“ Train Multiple Models â†“ Evaluate Models â†“ Production-Aware Model Selection â†“ Final Trained Pipeline

âš™ï¸ Data Preprocessing Strategy
Numeric Features
Missing values handled using median imputation
Features scaled using StandardScaler
Prevents dominance of large numeric values
Categorical Features
Missing values filled with most frequent category
Encoded using One-Hot Encoding
Sparse matrix output for memory efficiency
Rare categories grouped using min_frequency
High-Cardinality Protection
Categorical features with more than 50 unique values are dropped
Prevents dimensional explosion and memory crashes
ğŸ¤– Models Used
Classification
Logistic Regression
Stable
Interpretable
Outputs probabilities
Linear Support Vector Machine (LinearSVC)
Strong performance on sparse, high-dimensional data
Regression
Ridge Regression
Linear Support Vector Regression (SVR)
Models are selected dynamically based on detected task type.

ğŸ“Š Evaluation Metrics
Classification
Accuracy
Weighted F1-score (Primary metric)
F1-score is preferred because it balances precision and recall and handles class imbalance better than accuracy.

Regression
Root Mean Squared Error (RMSE)
RÂ² Score
ğŸ§  Model Selection Logic
Rank models by primary evaluation metric
Select top-N performing models
If multiple models perform similarly:
Prefer models that provide probability outputs
Prefer models that are more stable and production-friendly
This mirrors real-world ML decision-making.

ğŸš« Common Pitfalls Avoided
No preprocessing before train-test split (prevents data leakage)
No imputation of target labels
No dense conversion of sparse matrices
No accuracy-only optimization
No dataset-specific hardcoding
ğŸ› ï¸ Tech Stack
Python
Pandas, NumPy
scikit-learn
Jupyter Notebook
ğŸ“Œ Future Enhancements
Convert logic into an AutoMLLite class
Add cross-validation and stability scoring
Add dataset profiling summary
Build Streamlit UI
Add experiment tracking with MLflow
Deploy as an inference API
ğŸ“„ Resume Summary
Built a custom AutoML system that automatically preprocesses datasets, detects task type, evaluates multiple machine learning models, applies production-aware selection logic, and outputs a deployable trained pipeline.

âœ… Project Status
âœ” Core AutoML engine completed
âœ” Memory-safe preprocessing
âœ” Dynamic model selection
âœ” Production-aware decision logic
